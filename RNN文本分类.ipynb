{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "25715A338CB348B08D473C434B846AA2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torchtext.vocab as Vocab\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "import torch.utils.data as Data\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AC05E01AB8174177893EE229FD011345",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = r'/home/kesci/input/qiu_assignment74907/train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "55A05970D2AE4D6B99438A969A190359",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path,sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "85E96CBE8BB0404EBD0637F07041A5EC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "01480982646C4B9A8AF7EDE248ABE6E9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38    some of which occasionally amuses but none of ...\n",
       "39                                        some of which\n",
       "40                                                 some\n",
       "41                                             of which\n",
       "42                                                which\n",
       "43    occasionally amuses but none of which amounts ...\n",
       "44                                         occasionally\n",
       "45    amuses but none of which amounts to much of a ...\n",
       "46                                               amuses\n",
       "47         but none of which amounts to much of a story\n",
       "48                                                  but\n",
       "49             none of which amounts to much of a story\n",
       "50                                                 none\n",
       "51                  of which amounts to much of a story\n",
       "52                     which amounts to much of a story\n",
       "53                           amounts to much of a story\n",
       "54                                              amounts\n",
       "55                                   to much of a story\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Phrase[38:56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF7690298B664E9F9501AEA080F895E2",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 一、描述性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "8B89B03E9FC7404A858C171E4376CF31",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "E6FA2B2A126D4934857CB15A5DE05078",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "22A6AF9A34ED40428F83E3444C216EC9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "each_len = [len(x) for x in train_data.Phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "A0EBBAF185F0460DAF3B4C1DBBABA317",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len is 283 and average len is 40\n"
     ]
    }
   ],
   "source": [
    "average_len = int(sum(each_len)/len(each_len))\n",
    "print('Max len is {} and average len is {}'.format(max(each_len),average_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DD19A44A7264A149203EE81912F8F4E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 二、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "A3DDFECCEBA34C7189479FA6DC775221",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "        \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "        \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "D44C9A1264CC4EA699DC9BF939310003",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/156060 [00:02<105:54:18,  2.44s/it]/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:294: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "100%|██████████| 156060/156060 [00:32<00:00, 4774.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_sentences = clean_sentences(train_data)\n",
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "BC9229ADFB024D548B2BE409E6EC9789",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['is'],\n",
       " ['good', 'for', 'the', 'goose'],\n",
       " ['good'],\n",
       " ['for', 'the', 'goose'],\n",
       " ['for'],\n",
       " ['the', 'goose']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[20:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "DD79EBDC99E940089E1CE70569F56F2F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len is 48 and average len is 6\n"
     ]
    }
   ],
   "source": [
    "senten_len = [len(x) for x in train_sentences]\n",
    "ave_len = int(sum(senten_len)/len(senten_len))\n",
    "print('Max len is {} and average len is {}'.format(max(senten_len),ave_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "5065B2EBB26241C08E85E398F3E18DC8",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "E6B8EF3EB8384BCEAB8B788100771067",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_data.insert(0,'Phrases',train_sentences)\n",
    "preprocess_data.insert(1,'Sentiment',train_data['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "6A45D1E16A074C63B73F2EFECF1FE051",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[a, series, of, escapade, demonstrating, the, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapade, demonstrating, the, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[a]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[series]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[of, escapade, demonstrating, the, adage, that...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Phrases  Sentiment\n",
       "0  [a, series, of, escapade, demonstrating, the, ...          1\n",
       "1  [a, series, of, escapade, demonstrating, the, ...          2\n",
       "2                                        [a, series]          2\n",
       "3                                                [a]          2\n",
       "4                                           [series]          2\n",
       "5  [of, escapade, demonstrating, the, adage, that...          2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "20937B6D269E48E9A46AA446C9469754",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_data.to_csv('preprocess_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "6C34DE5E1DE64BD983BAB69BFEA466FA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-109-64e577fd40c0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-109-64e577fd40c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    textcnn参考https://www.cnblogs.com/mxp-neu/articles/9949409.html\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "textcnn参考https://www.cnblogs.com/mxp-neu/articles/9949409.html\n",
    "因为最后一层是max_pooling所以padding对其没有影响\n",
    "\n",
    "mask问题https://www.zhihu.com/question/305508138/answer/552710027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "41B0A81D4DB64A75AD330F14F4CABF36",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    156060 non-null int64\n",
      "Phrases       156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/home/kesci/work/preprocess_data')\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DCB2C6498DEA4DBB9B7FABE58C37AF2E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['is'],\n",
       " ['good', 'for', 'the', 'goose'],\n",
       " ['good'],\n",
       " ['for', 'the', 'goose'],\n",
       " ['for'],\n",
       " ['the', 'goose']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data.drop(columns = 'Unnamed: 0')\n",
    "reviews = []\n",
    "for review in df.Phrases:\n",
    "    reviews.append(eval(review))\n",
    "reviews[20:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C56844CDC3DC480187BC611A0B3538E5",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 三、建立词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0D9C8338C8374424880D0025EB2BC7EC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#建立词语索引，保留在数据集中至少出现5次的词\n",
    "counter = collections.Counter([tk for st in reviews for tk in st])\n",
    "vocab = Vocab.Vocab(counter, min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B7CCDC5C00A543BBBB9003F45B204B6C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 51633),\n",
       " ('a', 45066),\n",
       " ('of', 32702),\n",
       " ('and', 32177),\n",
       " ('to', 22761),\n",
       " ('it', 18785),\n",
       " ('s', 17447),\n",
       " ('in', 14006),\n",
       " ('is', 13476),\n",
       " ('that', 12338)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1B023AA10B1042749234201C52415A7F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_l = 48\n",
    "def pad(x):\n",
    "    return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n",
    "features = torch.tensor([pad([vocab.stoi[word] for word in words]) \n",
    "                    for words in reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5CA12ED65C974F5683461EEE8AE2C291",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'series']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BBC427212B204D418A073A572C76BB9A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3, 338,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2800E1D4C5214CB79064C27A6B2BBDD5",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor([train_data.Sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "10271051CBA04A3B8A344AFD601A63BA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = {}\n",
    "embeddings_file = '/home/kesci/input/qiu_assignment74907/glove.6B.50d.txt'\n",
    "with open(embeddings_file, \"r\", encoding=\"utf8\") as input_data:\n",
    "    for line in input_data:\n",
    "        line = line.split()\n",
    "        try:\n",
    "            float(line[1])\n",
    "            word = line[0]\n",
    "            embeddings[word] = line[1:]\n",
    "        except ValueError:\n",
    "            continue\n",
    "len(embeddings['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "B7AF3453F4754F4F83951B4EFC0946FF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#本来直接torch.tensor(embeddings[word], dtype = torch.float)\n",
    "#但是报错too many dimensions，不知如何解决，就先转换为np.array\n",
    "embedding_matrix = torch.zeros((num_words, 50))\n",
    "embedding_matrix[0]\n",
    "a = np.array(embeddings['the'],dtype = float)\n",
    "b = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "65570E9A3FF848D8930C45EA9FDC3409",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad\n",
      "There are 282 oov words.\n"
     ]
    }
   ],
   "source": [
    "num_words = len(vocab.itos)\n",
    "embedding_matrix = torch.zeros((num_words, 50))\n",
    "oov_count = 0 # out of vocabulary\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if word in embeddings:\n",
    "        word_embedding = np.array(embeddings[word],dtype = float)\n",
    "        embedding_matrix[i] = torch.tensor(word_embedding, dtype=torch.float64)\n",
    "    else:\n",
    "        if word == '<pad>':\n",
    "            print('pad')\n",
    "            continue\n",
    "        oov_count += 1\n",
    "        embedding_matrix[i] = torch.randn(50)\n",
    "print(\"There are %d oov words.\" % oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CA9861F52F0D424F8F37E77E5D0C2F24",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看一下生成的词向量\n",
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "359D8028BFE24A158FBFCEAFEF5E1926",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.418',\n",
       " '0.24968',\n",
       " '-0.41242',\n",
       " '0.1217',\n",
       " '0.34527',\n",
       " '-0.044457',\n",
       " '-0.49688',\n",
       " '-0.17862',\n",
       " '-0.00066023',\n",
       " '-0.6566',\n",
       " '0.27843',\n",
       " '-0.14767',\n",
       " '-0.55677',\n",
       " '0.14658',\n",
       " '-0.0095095',\n",
       " '0.011658',\n",
       " '0.10204',\n",
       " '-0.12792',\n",
       " '-0.8443',\n",
       " '-0.12181',\n",
       " '-0.016801',\n",
       " '-0.33279',\n",
       " '-0.1552',\n",
       " '-0.23131',\n",
       " '-0.19181',\n",
       " '-1.8823',\n",
       " '-0.76746',\n",
       " '0.099051',\n",
       " '-0.42125',\n",
       " '-0.19526',\n",
       " '4.0071',\n",
       " '-0.18594',\n",
       " '-0.52287',\n",
       " '-0.31681',\n",
       " '0.00059213',\n",
       " '0.0074449',\n",
       " '0.17778',\n",
       " '-0.15897',\n",
       " '0.012041',\n",
       " '-0.054223',\n",
       " '-0.29871',\n",
       " '-0.15749',\n",
       " '-0.34758',\n",
       " '-0.045637',\n",
       " '-0.44251',\n",
       " '0.18785',\n",
       " '0.0027849',\n",
       " '-0.18411',\n",
       " '-0.11514',\n",
       " '-0.78581']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7497FCD621CD42408D960E6FA1506445",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 四、建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "107787DAA5FF4A5080059E49B1B1C15C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: 在数据集上创建的词典，用于获取词典大小\n",
    "            embed_size: 嵌入维度大小\n",
    "            num_hiddens: 隐藏状态维度大小\n",
    "            num_layers: 隐藏层个数\n",
    "        '''\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        \n",
    "        # encoder-decoder framework\n",
    "        # bidirectional设为True即得到双向循环神经网络\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, \n",
    "                                hidden_size=num_hiddens, \n",
    "                                num_layers=num_layers,\n",
    "                                bidirectional=True)\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 5) # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "                                                   #总共有五类情感 \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n",
    "        @return:\n",
    "            outs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n",
    "        '''\n",
    "        # 因为LSTM需要将序列长度(seq_len)作为第一维，所以需要将输入转置\n",
    "        embeddings = self.embedding(inputs.permute(1, 0)) # (seq_len, batch_size, d)\n",
    "        # rnn.LSTM 返回输出、隐藏状态和记忆单元，格式如 outputs, (h, c)\n",
    "        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n",
    "        outs = self.decoder(encoding) # (batch_size, 2)\n",
    "        return outs\n",
    "\n",
    "embed_size, num_hiddens, num_layers = 50, 100, 2\n",
    "net = BiRNN(vocab, embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "1208EB2A751146EE8C8277938B6C70CA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2601,  0.1657, -0.1617,  ...,  0.4756, -0.8590,  0.3660],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
       "        ...,\n",
       "        [-0.8092, -0.0310,  0.5102,  ...,  0.0549, -0.1811,  1.4094],\n",
       "        [-0.4244, -0.0948, -0.1946,  ...,  0.3926,  0.8929, -0.2771],\n",
       "        [-1.6331,  0.3790, -1.1350,  ...,  1.6321, -1.1320,  0.4799]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将预训练好的词向量拷贝至embedding层\n",
    "net.embedding.weight.data.copy_(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F016C63300D46B799EF32953279A578",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 五、构建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2A7AC40C343747BD8E0975DB8AD04ADF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor(df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "71BDB69859F545FD8E8B31146D4012BB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = Data.TensorDataset(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7D582B09DED145D793E7C5135DCC6B7B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 48]) y torch.Size([64])\n",
      "#batches: 2439\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break\n",
    "print('#batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "BEA8D70E14A54A358CA124990CCD5813",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_iter,  net, loss, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y) \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "34002618F7C84850882227F381C4E27D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 0.7402, train acc 0.695, time 535.0 sec\n",
      "epoch 2, loss 0.3572, train acc 0.705, time 527.3 sec\n",
      "epoch 3, loss 0.2312, train acc 0.713, time 642.4 sec\n",
      "epoch 4, loss 0.1708, train acc 0.717, time 812.9 sec\n",
      "epoch 5, loss 0.1349, train acc 0.721, time 1117.8 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train(train_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "72E78C41C689431292E02BF34654141C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    '''\n",
    "    @params：\n",
    "        net: 训练好的模型\n",
    "        vocab: 在该数据集上创建的词典，用于将给定的单词序转换为单词下标的序列，从而输入模型\n",
    "        sentence: 需要分析情感的文本，以单词序列的形式给出\n",
    "    @return: 预测的结果，positive 为正面情绪文本，negative 为负面情绪文本\n",
    "    '''\n",
    "    device = list(net.parameters())[0].device # 读取模型所在的环境\n",
    "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
    "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'terrible'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
