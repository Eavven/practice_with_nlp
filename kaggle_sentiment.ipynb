{"cells":[{"outputs":[],"execution_count":null,"source":"# 查看当前挂载的数据集目录\n!ls /home/kesci/input/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0E1AA8B910DF4B6D949DA5C4A773106D"}},{"outputs":[],"execution_count":null,"source":"# 查看个人持久化工作区文件\n!ls /home/kesci/work/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B8B17817D44840A18ABD6C6DEC087F7D"}},{"outputs":[],"execution_count":null,"source":"# 查看当前kernerl下的package\n!pip list --format=columns","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D8E4C97DC84A477480C20C27AC0C0724"}},{"outputs":[],"execution_count":null,"source":"# 显示cell运行时长\n%load_ext klab-autotime","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"442EF2DC9F6D453783C1877FEEF7E316"}},{"metadata":{"id":"ED04E03F708946AE80AE6D87A626B57C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package wordnet to /home/kesci/nltk_data...\n","name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-3782926ae7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 )\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincr_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_or_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0;31m# Error messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mErrorMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mincr_download\u001b[0;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Handle Packages (delegate to a helper function).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_download_package\u001b[0;34m(self, info, download_dir, force)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mnum_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 16k blocks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m                     \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":"nltk.download('wordnet')","execution_count":105},{"metadata":{"id":"95F10D95D123460684D038C94A9A84A7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\nCollecting nltk\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n\u001b[K     |████████████████████████████████| 1.4MB 138kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (0.13.2)\nCollecting regex (from nltk)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/ae/e95597263be4f014e9389bddf94bc6d05f5c4dd42ac01e9a62b18553a40a/regex-2020.5.7-cp37-cp37m-manylinux2010_x86_64.whl (676kB)\n\u001b[K     |████████████████████████████████| 686kB 135kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.32.2)\nBuilding wheels for collected packages: nltk\n\u001b[33m  WARNING: Building wheel for nltk failed: [Errno 13] Permission denied: '/home/jovyan/.cache/pip/wheels'\u001b[0m\nFailed to build nltk\nInstalling collected packages: regex, nltk\n  Running setup.py install for nltk ... \u001b[?25ldone\n\u001b[?25hSuccessfully installed nltk-3.5 regex-2020.5.7\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}],"source":"pip install nltk","execution_count":1},{"metadata":{"id":"40CF3A93B8564DD9A11338C813B3AFFE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\nCollecting torchtext\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n\u001b[K     |████████████████████████████████| 71kB 208kB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.3.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext) (4.32.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext) (2.22.0)\nCollecting sentencepiece (from torchtext)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/9d/dcaaba6fcee6a5c3b36c465557720f088c29cdb5931bc8b4b2556394b3d0/sentencepiece-0.1.86-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n\u001b[K     |████████████████████████████████| 1.0MB 61kB/s eta 0:00:014\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.17.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.12.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (1.25.3)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2019.9.11)\nInstalling collected packages: sentencepiece, torchtext\nSuccessfully installed sentencepiece-0.1.86 torchtext-0.6.0\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}],"source":"pip install torchtext ","execution_count":2},{"metadata":{"id":"25715A338CB348B08D473C434B846AA2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import os\nimport sys\nimport torch\nfrom torch.nn import functional as F\nimport numpy as np\nfrom torchtext import data\nfrom torchtext import datasets\nimport torchtext.vocab as Vocab\nfrom torchtext.vocab import Vectors, GloVe\nimport torch.utils.data as Data\nfrom torch import nn\nimport pandas as pd\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nfrom bs4 import BeautifulSoup\nimport re\nfrom tqdm import tqdm\nimport collections\nimport time","execution_count":3},{"metadata":{"id":"AC05E01AB8174177893EE229FD011345","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import pandas as pd\npath = r'/home/kesci/input/qiu_assignment74907/train.tsv'","execution_count":1},{"metadata":{"id":"55A05970D2AE4D6B99438A969A190359","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"train_data = pd.read_csv(path,sep = '\\t')","execution_count":2},{"metadata":{"id":"85E96CBE8BB0404EBD0637F07041A5EC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"   PhraseId  SentenceId                                             Phrase  \\\n0         1           1  A series of escapades demonstrating the adage ...   \n1         2           1  A series of escapades demonstrating the adage ...   \n2         3           1                                           A series   \n3         4           1                                                  A   \n4         5           1                                             series   \n5         6           1  of escapades demonstrating the adage that what...   \n\n   Sentiment  \n0          1  \n1          2  \n2          2  \n3          2  \n4          2  \n5          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>of escapades demonstrating the adage that what...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"transient":{},"execution_count":3}],"source":"train_data.head(6)","execution_count":3},{"metadata":{"id":"01480982646C4B9A8AF7EDE248ABE6E9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"38    some of which occasionally amuses but none of ...\n39                                        some of which\n40                                                 some\n41                                             of which\n42                                                which\n43    occasionally amuses but none of which amounts ...\n44                                         occasionally\n45    amuses but none of which amounts to much of a ...\n46                                               amuses\n47         but none of which amounts to much of a story\n48                                                  but\n49             none of which amounts to much of a story\n50                                                 none\n51                  of which amounts to much of a story\n52                     which amounts to much of a story\n53                           amounts to much of a story\n54                                              amounts\n55                                   to much of a story\nName: Phrase, dtype: object"},"transient":{},"execution_count":10}],"source":"train_data.Phrase[38:56]","execution_count":10},{"metadata":{"id":"EF7690298B664E9F9501AEA080F895E2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 一、描述性分析"},{"metadata":{"id":"8B89B03E9FC7404A858C171E4376CF31","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 156060 entries, 0 to 156059\nData columns (total 4 columns):\nPhraseId      156060 non-null int64\nSentenceId    156060 non-null int64\nPhrase        156060 non-null object\nSentiment     156060 non-null int64\ndtypes: int64(3), object(1)\nmemory usage: 4.8+ MB\n","name":"stdout"}],"source":"train_data.info()","execution_count":84},{"metadata":{"id":"E6FA2B2A126D4934857CB15A5DE05078","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64"},"transient":{},"execution_count":85}],"source":"train_data.Sentiment.value_counts()","execution_count":85},{"metadata":{"id":"22A6AF9A34ED40428F83E3444C216EC9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"each_len = [len(x) for x in train_data.Phrase]","execution_count":86},{"metadata":{"id":"A0EBBAF185F0460DAF3B4C1DBBABA317","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Max len is 283 and average len is 40\n","name":"stdout"}],"source":"average_len = int(sum(each_len)/len(each_len))\nprint('Max len is {} and average len is {}'.format(max(each_len),average_len))","execution_count":87},{"metadata":{"id":"1DD19A44A7264A149203EE81912F8F4E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 二、数据预处理"},{"metadata":{"id":"A3DDFECCEBA34C7189479FA6DC775221","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def clean_sentences(df):\n    reviews = []\n    for sent in tqdm(df['Phrase']):\n        #remove html content\n        review_text = BeautifulSoup(sent).get_text()\n        \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n        \n        #tokenize the sentences\n        words = word_tokenize(review_text.lower())\n        \n        #lemmatize each word to its lemma\n        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n    \n        reviews.append(lemma_words)\n\n    return(reviews)","execution_count":88},{"metadata":{"id":"D44C9A1264CC4EA699DC9BF939310003","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"  0%|          | 1/156060 [00:02<105:54:18,  2.44s/it]/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:294: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n  ' Beautiful Soup.' % markup)\n100%|██████████| 156060/156060 [00:32<00:00, 4774.06it/s]","name":"stderr"},{"output_type":"stream","text":"156060\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}],"source":"train_sentences = clean_sentences(train_data)\nprint(len(train_sentences))","execution_count":102},{"metadata":{"id":"BC9229ADFB024D548B2BE409E6EC9789","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[['is'],\n ['good', 'for', 'the', 'goose'],\n ['good'],\n ['for', 'the', 'goose'],\n ['for'],\n ['the', 'goose']]"},"transient":{},"execution_count":103}],"source":"train_sentences[20:26]","execution_count":103},{"metadata":{"id":"DD79EBDC99E940089E1CE70569F56F2F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Max len is 48 and average len is 6\n","name":"stdout"}],"source":"senten_len = [len(x) for x in train_sentences]\nave_len = int(sum(senten_len)/len(senten_len))\nprint('Max len is {} and average len is {}'.format(max(senten_len),ave_len))","execution_count":104},{"metadata":{"id":"5065B2EBB26241C08E85E398F3E18DC8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"preprocess_data = pd.DataFrame()","execution_count":105},{"metadata":{"id":"E6B8EF3EB8384BCEAB8B788100771067","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"preprocess_data.insert(0,'Phrases',train_sentences)\npreprocess_data.insert(1,'Sentiment',train_data['Sentiment'])","execution_count":106},{"metadata":{"id":"6A45D1E16A074C63B73F2EFECF1FE051","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"                                             Phrases  Sentiment\n0  [a, series, of, escapade, demonstrating, the, ...          1\n1  [a, series, of, escapade, demonstrating, the, ...          2\n2                                        [a, series]          2\n3                                                [a]          2\n4                                           [series]          2\n5  [of, escapade, demonstrating, the, adage, that...          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Phrases</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>[a, series, of, escapade, demonstrating, the, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>[a, series, of, escapade, demonstrating, the, ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>[a, series]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>[a]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>[series]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>[of, escapade, demonstrating, the, adage, that...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"transient":{},"execution_count":107}],"source":"preprocess_data.head(6)","execution_count":107},{"metadata":{"id":"20937B6D269E48E9A46AA446C9469754","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"preprocess_data.to_csv('preprocess_data')","execution_count":108},{"metadata":{"id":"6C34DE5E1DE64BD983BAB69BFEA466FA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-109-64e577fd40c0>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-109-64e577fd40c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    textcnn参考https://www.cnblogs.com/mxp-neu/articles/9949409.html\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":"textcnn参考https://www.cnblogs.com/mxp-neu/articles/9949409.html\n因为最后一层是max_pooling所以padding对其没有影响\n\nmask问题https://www.zhihu.com/question/305508138/answer/552710027","execution_count":109},{"metadata":{"id":"41B0A81D4DB64A75AD330F14F4CABF36","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 156060 entries, 0 to 156059\nData columns (total 3 columns):\nUnnamed: 0    156060 non-null int64\nPhrases       156060 non-null object\nSentiment     156060 non-null int64\ndtypes: int64(2), object(1)\nmemory usage: 3.6+ MB\n","name":"stdout"}],"source":"train_data = pd.read_csv('/home/kesci/work/preprocess_data')\ntrain_data.info()","execution_count":4},{"metadata":{"id":"DCB2C6498DEA4DBB9B7FABE58C37AF2E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[['is'],\n ['good', 'for', 'the', 'goose'],\n ['good'],\n ['for', 'the', 'goose'],\n ['for'],\n ['the', 'goose']]"},"transient":{},"execution_count":5}],"source":"df = train_data.drop(columns = 'Unnamed: 0')\nreviews = []\nfor review in df.Phrases:\n    reviews.append(eval(review))\nreviews[20:26]","execution_count":5},{"metadata":{"id":"C56844CDC3DC480187BC611A0B3538E5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 三、建立词向量"},{"metadata":{"id":"0D9C8338C8374424880D0025EB2BC7EC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#建立词语索引，保留在数据集中至少出现5次的词\ncounter = collections.Counter([tk for st in reviews for tk in st])\nvocab = Vocab.Vocab(counter, min_freq=5)","execution_count":6},{"metadata":{"id":"B7CCDC5C00A543BBBB9003F45B204B6C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[('the', 51633),\n ('a', 45066),\n ('of', 32702),\n ('and', 32177),\n ('to', 22761),\n ('it', 18785),\n ('s', 17447),\n ('in', 14006),\n ('is', 13476),\n ('that', 12338)]"},"transient":{},"execution_count":7}],"source":"counter.most_common(10)","execution_count":7},{"metadata":{"id":"1B023AA10B1042749234201C52415A7F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"max_l = 48\ndef pad(x):\n    return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\nfeatures = torch.tensor([pad([vocab.stoi[word] for word in words]) \n                    for words in reviews])","execution_count":8},{"metadata":{"id":"5CA12ED65C974F5683461EEE8AE2C291","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['a', 'series']"},"transient":{},"execution_count":9}],"source":"reviews[2]","execution_count":9},{"metadata":{"id":"BBC427212B204D418A073A572C76BB9A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([  3, 338,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0])"},"transient":{},"execution_count":10}],"source":"features[2]","execution_count":10},{"metadata":{"id":"2800E1D4C5214CB79064C27A6B2BBDD5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"labels = torch.tensor([train_data.Sentiment])","execution_count":11},{"metadata":{"id":"10271051CBA04A3B8A344AFD601A63BA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"50"},"transient":{},"execution_count":12}],"source":"embeddings = {}\nembeddings_file = '/home/kesci/input/qiu_assignment74907/glove.6B.50d.txt'\nwith open(embeddings_file, \"r\", encoding=\"utf8\") as input_data:\n    for line in input_data:\n        line = line.split()\n        try:\n            float(line[1])\n            word = line[0]\n            embeddings[word] = line[1:]\n        except ValueError:\n            continue\nlen(embeddings['the'])","execution_count":12},{"metadata":{"id":"B7AF3453F4754F4F83951B4EFC0946FF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#本来直接torch.tensor(embeddings[word], dtype = torch.float)\n#但是报错too many dimensions，不知如何解决，就先转换为np.array\nembedding_matrix = torch.zeros((num_words, 50))\nembedding_matrix[0]\na = np.array(embeddings['the'],dtype = float)\nb = torch.tensor(a)","execution_count":15},{"metadata":{"id":"65570E9A3FF848D8930C45EA9FDC3409","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"pad\nThere are 282 oov words.\n","name":"stdout"}],"source":"num_words = len(vocab.itos)\nembedding_matrix = torch.zeros((num_words, 50))\noov_count = 0 # out of vocabulary\nfor i, word in enumerate(vocab.itos):\n    if word in embeddings:\n        word_embedding = np.array(embeddings[word],dtype = float)\n        embedding_matrix[i] = torch.tensor(word_embedding, dtype=torch.float64)\n    else:\n        if word == '<pad>':\n            print('pad')\n            continue\n        oov_count += 1\n        embedding_matrix[i] = torch.randn(50)\nprint(\"There are %d oov words.\" % oov_count)","execution_count":16},{"metadata":{"id":"CA9861F52F0D424F8F37E77E5D0C2F24","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"},"transient":{},"execution_count":17}],"source":"#查看一下生成的词向量\nembedding_matrix[2]","execution_count":17},{"metadata":{"id":"359D8028BFE24A158FBFCEAFEF5E1926","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['0.418',\n '0.24968',\n '-0.41242',\n '0.1217',\n '0.34527',\n '-0.044457',\n '-0.49688',\n '-0.17862',\n '-0.00066023',\n '-0.6566',\n '0.27843',\n '-0.14767',\n '-0.55677',\n '0.14658',\n '-0.0095095',\n '0.011658',\n '0.10204',\n '-0.12792',\n '-0.8443',\n '-0.12181',\n '-0.016801',\n '-0.33279',\n '-0.1552',\n '-0.23131',\n '-0.19181',\n '-1.8823',\n '-0.76746',\n '0.099051',\n '-0.42125',\n '-0.19526',\n '4.0071',\n '-0.18594',\n '-0.52287',\n '-0.31681',\n '0.00059213',\n '0.0074449',\n '0.17778',\n '-0.15897',\n '0.012041',\n '-0.054223',\n '-0.29871',\n '-0.15749',\n '-0.34758',\n '-0.045637',\n '-0.44251',\n '0.18785',\n '0.0027849',\n '-0.18411',\n '-0.11514',\n '-0.78581']"},"transient":{},"execution_count":18}],"source":"embeddings['the']","execution_count":18},{"metadata":{"id":"7497FCD621CD42408D960E6FA1506445","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 四、建立模型"},{"metadata":{"id":"107787DAA5FF4A5080059E49B1B1C15C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"class BiRNN(nn.Module):\n    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n        '''\n        @params:\n            vocab: 在数据集上创建的词典，用于获取词典大小\n            embed_size: 嵌入维度大小\n            num_hiddens: 隐藏状态维度大小\n            num_layers: 隐藏层个数\n        '''\n        super(BiRNN, self).__init__()\n        self.embedding = nn.Embedding(len(vocab), embed_size)\n        \n        # encoder-decoder framework\n        # bidirectional设为True即得到双向循环神经网络\n        self.encoder = nn.LSTM(input_size=embed_size, \n                                hidden_size=num_hiddens, \n                                num_layers=num_layers,\n                                bidirectional=True)\n        self.decoder = nn.Linear(4*num_hiddens, 5) # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n                                                   #总共有五类情感 \n    def forward(self, inputs):\n        '''\n        @params:\n            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n        @return:\n            outs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n        '''\n        # 因为LSTM需要将序列长度(seq_len)作为第一维，所以需要将输入转置\n        embeddings = self.embedding(inputs.permute(1, 0)) # (seq_len, batch_size, d)\n        # rnn.LSTM 返回输出、隐藏状态和记忆单元，格式如 outputs, (h, c)\n        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n        encoding = torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n        outs = self.decoder(encoding) # (batch_size, 2)\n        return outs\n\nembed_size, num_hiddens, num_layers = 50, 100, 2\nnet = BiRNN(vocab, embed_size, num_hiddens, num_layers)","execution_count":93},{"metadata":{"id":"1208EB2A751146EE8C8277938B6C70CA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([[ 0.2601,  0.1657, -0.1617,  ...,  0.4756, -0.8590,  0.3660],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n        ...,\n        [-0.8092, -0.0310,  0.5102,  ...,  0.0549, -0.1811,  1.4094],\n        [-0.4244, -0.0948, -0.1946,  ...,  0.3926,  0.8929, -0.2771],\n        [-1.6331,  0.3790, -1.1350,  ...,  1.6321, -1.1320,  0.4799]])"},"transient":{},"execution_count":94}],"source":"#将预训练好的词向量拷贝至embedding层\nnet.embedding.weight.data.copy_(embedding_matrix)","execution_count":94},{"metadata":{"id":"8F016C63300D46B799EF32953279A578","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 五、构建训练数据"},{"metadata":{"id":"2A7AC40C343747BD8E0975DB8AD04ADF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"labels = torch.tensor(df.Sentiment)","execution_count":21},{"metadata":{"id":"71BDB69859F545FD8E8B31146D4012BB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"train_set = Data.TensorDataset(features, labels)","execution_count":22},{"metadata":{"id":"7D582B09DED145D793E7C5135DCC6B7B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"X torch.Size([64, 48]) y torch.Size([64])\n#batches: 2439\n","name":"stdout"}],"source":"batch_size = 64\ntrain_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\nfor X, y in train_iter:\n    print('X', X.shape, 'y', y.shape)\n    break\nprint('#batches:', len(train_iter))","execution_count":23},{"metadata":{"id":"BEA8D70E14A54A358CA124990CCD5813","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def train(train_iter,  net, loss, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"training on \", device)\n    batch_count = 0\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y) \n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, time.time() - start))\n","execution_count":138},{"metadata":{"id":"34002618F7C84850882227F381C4E27D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"training on  cpu\nepoch 1, loss 0.7402, train acc 0.695, time 535.0 sec\nepoch 2, loss 0.3572, train acc 0.705, time 527.3 sec\nepoch 3, loss 0.2312, train acc 0.713, time 642.4 sec\nepoch 4, loss 0.1708, train acc 0.717, time 812.9 sec\nepoch 5, loss 0.1349, train acc 0.721, time 1117.8 sec\n","name":"stdout"}],"source":"lr, num_epochs = 0.01, 5\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\nloss = nn.CrossEntropyLoss()\n\ntrain(train_iter, net, loss, optimizer, device, num_epochs)","execution_count":139},{"metadata":{"id":"72E78C41C689431292E02BF34654141C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([0])"},"transient":{},"execution_count":142}],"source":"def predict_sentiment(net, vocab, sentence):\n    '''\n    @params：\n        net: 训练好的模型\n        vocab: 在该数据集上创建的词典，用于将给定的单词序转换为单词下标的序列，从而输入模型\n        sentence: 需要分析情感的文本，以单词序列的形式给出\n    @return: 预测的结果，positive 为正面情绪文本，negative 为负面情绪文本\n    '''\n    device = list(net.parameters())[0].device # 读取模型所在的环境\n    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n    dict = {\n        tensor([0]):'negative'\n       tensor([1]):'somewhat negative'\n        tensor([2]):'neutral'\n        tensor([3]):'somewhat positive'\n        tensor([4]):'positive'\n        }\n    return dict(label)\n\npredict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'terrible'])","execution_count":142},{"metadata":{"id":"BB12DF5C7C9C4FA4879E9929CA134E30","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-2-7f9a532762e0>, line 3)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-7f9a532762e0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    tensor[1]:'somewhat negative'\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":"dict = {\n        tensor[0]:'negative'\n       tensor[1]:'somewhat negative'\n        tensor[2]:'neutral'\n        tensor[3]:'somewhat positive'\n        tensor[4]:'positive'\n        }","execution_count":2},{"metadata":{"id":"52F3866FDADB4A5096FFC8D6DF429E4E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'num_hiddens' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-93b992cef56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mnet_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'num_hiddens' is not defined"]}],"source":"class TextCNN(nn.Module):\n    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n        '''\n        @params:\n            vocab: 在数据集上创建的词典，用于获取词典大小\n            embed_size: 嵌入维度大小\n            kernel_sizes: 卷积核大小列表\n            num_channels: 卷积通道数列表\n        '''\n        super(TextCNN, self).__init__()\n        self.embedding = nn.Embedding(len(vocab), embed_size) # 参与训练的嵌入层\n        self.constant_embedding = nn.Embedding(len(vocab), embed_size) # 不参与训练的嵌入层\n        \n        self.pool = GlobalMaxPool1d() # 时序最大池化层没有权重，所以可以共用一个实例\n        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n        for c, k in zip(num_channels, kernel_sizes):\n            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, \n                                        out_channels = c, \n                                        kernel_size = k))\n            \n        self.decoder = nn.Linear(sum(num_channels), 5)\n        self.dropout = nn.Dropout(0.5) # 丢弃层用于防止过拟合\n\n    def forward(self, inputs):\n        '''\n        @params:\n            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n        @return:\n            outputs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n        '''\n        embeddings = torch.cat((\n            self.embedding(inputs), \n            self.constant_embedding(inputs)), dim=2) # (batch_size, seq_len, 2*embed_size)\n        # 根据一维卷积层要求的输入格式，需要将张量进行转置\n        embeddings = embeddings.permute(0, 2, 1) # (batch_size, 2*embed_size, seq_len)\n        \n        encoding = torch.cat([\n            self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n        # encoding = []\n        # for conv in self.convs:\n        #     out = conv(embeddings) # (batch_size, out_channels, seq_len-kernel_size+1)\n        #     out = self.pool(F.relu(out)) # (batch_size, out_channels, 1)\n        #     encoding.append(out.squeeze(-1)) # (batch_size, out_channels)\n        # encoding = torch.cat(encoding) # (batch_size, out_channels_sum)\n        \n        # 应用丢弃法后使用全连接层得到输出\n        outputs = self.decoder(self.dropout(encoding))\n        return outputs\nembed_size = 50    \nnet_2 = TextCNN(vocab, embed_size, num_hiddens, num_layers)\n","execution_count":25},{"metadata":{"id":"081E74619F394051990D1CD203DA8F7D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"net_2.embedding.weight.data.copy_(embedding_matrix)","execution_count":null},{"metadata":{"id":"8516514440D5448B83C6E407D9FA1A74","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'net' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a7ea0adfa540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"]}],"source":"lr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\nloss = nn.CrossEntropyLoss()\ntrain(train_iter, net, loss, optimizer, device, num_epochs)","execution_count":20},{"metadata":{"id":"E21ACCAD015544658F11E7850EBD5834","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}